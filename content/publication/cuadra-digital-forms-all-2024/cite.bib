@article{cuadraDigitalFormsAll2024,
 abstract = {Digital forms help us access services and opportunities, but they are not equally accessible to everyone, such as older adults or those with sensory impairments. Large language models (LLMs) and multimodal interfaces offer a unique opportunity to increase form accessibility. Informed by prior literature and needfinding, we built a holistic multimodal LLM agent for health data entry. We describe the process of designing and building our system, and the results of a study with older adults (N =10). All participants, regardless of age or disability status, were able to complete a standard 47-question form independently using our system---one blind participant said it was "a prayer answered." Our video analysis revealed how different modalities provided alternative interaction paths in complementary ways (e.g., the buttons helped resolve transcription errors and speech helped provide more options when the pre-canned answer choices were insufficient). We highlight key design guidelines, such as designing systems that dynamically adapt to individual needs.},
 author = {Cuadra, Andrea and Breuch, Justine and Estrada, Samantha and Ihim, David and Hung, Isabelle and Askaryar, Derek and Hassanien, Marwan and Fessele, Kristen L. and Landay, James A.},
 doi = {10.1145/3659624},
 file = {/Users/yiyangwang/Zotero/storage/N7BRA228/Cuadra et al. - 2024 - Digital Forms for All A Holistic Multimodal Large Language Model Agent for Health Data Entry.pdf},
 issn = {2474-9567},
 journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
 langid = {english},
 month = {May},
 number = {2},
 pages = {1--39},
 shorttitle = {Digital Forms for All},
 title = {Digital Forms for All: A Holistic Multimodal Large Language Model Agent for Health Data Entry},
 urldate = {2025-05-14},
 volume = {8},
 year = {2024}
}
